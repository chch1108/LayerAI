import streamlit as st
import pandas as pd
import zipfile
import os
import tempfile
from model_train import load_model_and_predict, INPUT_FEATURES
from llm_recommender import get_llm_recommendation

st.set_page_config(page_title="3D åˆ—å°å›æµæª¢æ¸¬", layout="wide")
st.title("âš™ï¸ 3D åˆ—å°å›æµæª¢æ¸¬èˆ‡ AI å„ªåŒ–å»ºè­°")

uploaded_file = st.file_uploader("è«‹ä¸Šå‚³åˆ—å°åœ–æª” ZIP (.zip)", type=['zip'])

def extract_images_from_zip(zip_path, extract_dir):
    """è§£å£“ ZIP ä¸¦å–å¾— PNG åœ–ç‰‡è·¯å¾‘"""
    imgs = []
    filenames = []
    with zipfile.ZipFile(zip_path) as zf:
        for name in zf.namelist():
            if name.lower().endswith(".png"):
                # ä¿ç•™åŸå§‹åç¨±ï¼Œé¿å…é‡è¤‡æ™‚åŠ ä¸Š _1, _2
                base = os.path.basename(name)
                if base in filenames:
                    continue  # å·²å­˜åœ¨å‰‡è·³é
                zf.extract(name, path=extract_dir)
                imgs.append(os.path.join(extract_dir, name))
                filenames.append(base)
    return imgs, filenames

if uploaded_file:
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            zip_path = os.path.join(tmpdir, "slices.zip")
            with open(zip_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            st.info("è§£å£“ä¸¦è®€å–åˆ‡ç‰‡ä¸­...")
            imgs, filenames = extract_images_from_zip(zip_path, tmpdir)
            if not imgs:
                st.error("ZIP å…§æ²’æœ‰ PNG åœ–ç‰‡")
            else:
                st.success(f"è®€å– {len(imgs)} å¼µåˆ‡ç‰‡")
                # é¸æ“‡åœ–å±¤
                layer_choice_base = st.selectbox("é¸æ“‡è¦æª¢æ¸¬çš„åœ–å±¤", filenames)
                layer_choice_full = imgs[filenames.index(layer_choice_base)]

                # --- æ¨¡æ“¬è®€å–åœ–æª”å°æ‡‰ç‰¹å¾µ ---
                input_data = {
                    'ææ–™é»åº¦ (cps)': 1000,
                    'æŠ¬å‡é«˜åº¦(Î¼m)': 50,
                    'æŠ¬å‡é€Ÿåº¦(Î¼m/s)': 20,
                    'ç­‰å¾…æ™‚é–“(s)': 5,
                    'ä¸‹é™é€Ÿåº¦((Î¼m)/s)': 15,
                    'å½¢ç‹€': 'æ–¹å½¢',
                    'é¢ç©(mm?)': 200,
                    'å‘¨é•·(mm)': 60,
                    'æ°´åŠ›ç›´å¾‘(mm)': 10
                }
                final_input_data = {feat: input_data.get(feat) for feat in INPUT_FEATURES}
                input_df = pd.DataFrame([final_input_data])

                # --- Run Prediction ---
                try:
                    prediction, importances = load_model_and_predict(input_df)
                    
                    if prediction == 0:
                        st.success("âœ… **é æ¸¬æˆåŠŸï¼šæ¨¹è„‚å›æµå®Œå…¨**")
                        st.write("ç›®å‰çš„åƒæ•¸è¨­å®šå®‰å…¨ï¼Œå¯ä»¥ç¹¼çºŒåˆ—å°ã€‚")
                    else:
                        st.error("ğŸš¨ **é æ¸¬å¤±æ•—ï¼šæ¨¹è„‚å›æµä¸å®Œå…¨**")
                        st.write("åµæ¸¬åˆ°æ½›åœ¨åˆ—å°å¤±æ•—é¢¨éšªï¼Œæ­£åœ¨ç”Ÿæˆ AI å»ºè­°...")
                        with st.spinner("æ­£åœ¨ç”Ÿæˆ AI å»ºè­°..."):
                            recommendation = get_llm_recommendation(final_input_data, importances)
                            st.markdown("---")
                            st.subheader("ğŸ¤– AI å„ªåŒ–å»ºè­°")
                            st.markdown(recommendation)

                except FileNotFoundError as e:
                    st.error(f"æ¨¡å‹æ–‡ä»¶éºå¤±ï¼š{e}\nè«‹å…ˆåŸ·è¡Œ `python model_train.py` è¨“ç·´æ¨¡å‹ã€‚")
                except Exception as e:
                    st.error(f"é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

    except Exception as e:
        st.error(f"ZIP æª”æ¡ˆè®€å–å¤±æ•—ï¼š{e}")
