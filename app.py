import streamlit as st
import tempfile, os, io, zipfile
import pandas as pd
import numpy as np
import plotly.express as px
from PIL import Image

# internal modules
from image_processor import (
    extract_images_from_zip,
    batch_extract_features,
    suggest_parameters_for_layers_with_model
)
from model_train import load_model_and_predict
from llm_recommender import get_llm_recommendation, get_low_risk_message
from image_editor_level1 import flow_simulation_overlay

# ----------------- Page config & cute theme -----------------
st.set_page_config(page_title="ğŸ¨ LayerAI â€” Fun Edition", layout="wide")
st.markdown(
    """
    <style>
    /* gradient background */
    .stApp { 
        background: linear-gradient(135deg, #a1c4fd, #c2e9fb); 
        color: #0f1720;
    }
    .block-container { padding: 1rem 2rem; }
    h1, h2, h3 { color: #0f1720; }
    .stButton>button { background-color:#ff8c94; color:white; border-radius:12px; font-weight:bold; }
    .stDownloadButton>button { background-color:#f6cd61; color:#0f1720; border-radius:12px; font-weight:bold; }
    .stSidebar .sidebar-content { background: #f0f4f8; color:#0f1720; }
    </style>
    """,
    unsafe_allow_html=True
)

st.title("ğŸ‰ LayerAI â€” å¤šå±¤é¢¨éšªåˆ†æ & AI å»ºè­° ğŸ’¡")

# ----------------- Sidebar -----------------
st.sidebar.header("âš™ï¸ æ§åˆ¶é¢æ¿")
st.sidebar.markdown("**è¼¸å…¥è£½ç¨‹åƒæ•¸**ï¼ˆå°‡å¥—ç”¨åˆ°æ¯å±¤ï¼‰")

viscosity = st.sidebar.number_input("ææ–™é»åº¦ (cps) ğŸ§ª", 50, 1000, 150, 10)
lift_height = st.sidebar.number_input("æŠ¬å‡é«˜åº¦ (Î¼m) â¬†ï¸", 500, 8000, 1500, 100)
lift_speed = st.sidebar.number_input("æŠ¬å‡é€Ÿåº¦ (Î¼m/s) ğŸš€", 100, 8000, 700, 50)
wait_time = st.sidebar.number_input("ç­‰å¾…æ™‚é–“ (s) â³", 0.0, 10.0, 0.5, 0.1)
down_speed = st.sidebar.number_input("ä¸‹é™é€Ÿåº¦ (Î¼m/s) â¬‡ï¸", 1000, 10000, 4000, 500)

uploaded = st.sidebar.file_uploader("ğŸ“¦ ä¸Šå‚³åˆ‡ç‰‡ ZIP æª”", type=["zip"])
threshold = st.sidebar.slider("é«˜é¢¨éšªåˆ¤å®šé–¾å€¼ âš ï¸", 0.0, 1.0, 0.5, 0.01)
run_btn = st.sidebar.button("ğŸš€ é–‹å§‹åˆ†æ")

# ----------------- Page selector -----------------
if "page" not in st.session_state:
    st.session_state.page = "Prediction"
st.session_state.page = st.sidebar.radio("ğŸ“„ é é¢é¸æ“‡", 
                                         ["Prediction", "Visuals", "AI Suggestions", "Summary"], 
                                         index=["Prediction","Visuals","AI Suggestions","Summary"].index(st.session_state.page))

# ----------------- session_state init -----------------
for key in ["results_df","llm_results","auto_tune_results","overlays"]:
    if key not in st.session_state:
        st.session_state[key] = {} if "results" in key else []
st.session_state.threshold = threshold

# ----------------- fallback auto-tune -----------------
def fallback_suggest_parameters(results_df, threshold=0.5):
    rows = []
    for _, r in results_df.iterrows():
        orig = float(r["prob"])
        layer = int(r["layer"])
        if orig >= threshold:
            cand = {"wait_time": round(wait_time + 0.4,3), "lift_height": lift_height, "lift_speed": max(50, lift_speed-50)}
            suggested_prob = max(0.0, orig - 0.12)
        else:
            cand = {"wait_time": wait_time, "lift_height": lift_height, "lift_speed": lift_speed}
            suggested_prob = orig
        rows.append({"layer": layer, "filename": r["filename"], "orig_prob": orig, "suggested_params": cand, "suggested_prob": suggested_prob})
    return pd.DataFrame(rows)

# ----------------- Run analysis -----------------
if run_btn:
    if uploaded is None:
        st.sidebar.error("âš ï¸ è«‹å…ˆä¸Šå‚³åˆ‡ç‰‡ ZIP")
    else:
        with tempfile.TemporaryDirectory() as tmpdir:
            zip_path = os.path.join(tmpdir, "slices.zip")
            with open(zip_path, "wb") as f:
                f.write(uploaded.getbuffer())

            imgs, filenames = extract_images_from_zip(zip_path, tmpdir)
            if len(imgs) == 0:
                st.error("âŒ ZIP å…§æ²’æœ‰æœ‰æ•ˆåœ–ç‰‡")
            else:
                st.success(f"âœ… è®€å– {len(imgs)} å¼µåˆ‡ç‰‡")
                feats = batch_extract_features(imgs, filenames)
                records = []
                st.session_state.overlays = []

                for img, feat in zip(imgs, feats):
                    input_data = {
                        'ææ–™é»åº¦ (cps)': viscosity,
                        'æŠ¬å‡é«˜åº¦(Î¼m)': lift_height,
                        'æŠ¬å‡é€Ÿåº¦(Î¼m/s)': lift_speed,
                        'ç­‰å¾…æ™‚é–“(s)': wait_time,
                        'ä¸‹é™é€Ÿåº¦((Î¼m)/s)': down_speed,
                        'é¢ç©(mm?)': feat['area'],
                        'å‘¨é•·(mm)': feat['perimeter'],
                        'æ°´åŠ›ç›´å¾‘(mm)': feat['hydraulic_diameter'],
                    }
                    pred, importances = load_model_and_predict(pd.DataFrame([input_data]))
                    try:
                        top3 = [n for n,_ in sorted(importances.items(), key=lambda x:x[1], reverse=True)[:3]]
                    except:
                        top3 = []

                    records.append({
                        "layer": int(feat["layer"]),
                        "filename": feat["filename"],
                        "prob": float(pred),
                        "top3_features": ", ".join(top3),
                        "params": input_data,
                        "importances": importances
                    })

                    if float(pred) >= threshold:
                        ov = flow_simulation_overlay(img, alpha=0.55)
                        buf = io.BytesIO()
                        ov.save(buf, format="PNG")
                        st.session_state.overlays.append((int(feat["layer"]), buf.getvalue()))

                st.session_state.results_df = pd.DataFrame(records).sort_values("layer").reset_index(drop=True)
                st.session_state.llm_results = {}
                st.session_state.auto_tune_results = {}
                st.success("ğŸ¯ é€å±¤é æ¸¬å®Œæˆï¼åˆ‡æ›é é¢æŸ¥çœ‹è©³ç´°çµæœ")
                st.session_state.page = "Prediction"

# ----------------- Render pages -----------------
if st.session_state.results_df is None:
    st.info("â„¹ï¸ å°šæœªåˆ†æï¼Œè«‹ä¸Šå‚³ ZIP ä¸¦æŒ‰ã€Œé–‹å§‹åˆ†æã€")
else:
    df = st.session_state.results_df.copy()

    # Prediction page
    if st.session_state.page == "Prediction":
        st.header("ğŸ“ Prediction â€” é€å±¤é æ¸¬")
        show_df = df[["layer","filename","prob","top3_features"]].copy()
        show_df["prob"] = show_df["prob"].map(lambda x:f"{x:.3f}")
        st.dataframe(show_df, use_container_width=True)

        st.markdown("### ğŸ”§ Auto-Tune å¿«é€Ÿæ“ä½œ")
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ä¸€éµ Auto-Tune é«˜é¢¨éšªå±¤"):
                try:
                    suggestion_df = suggest_parameters_for_layers_with_model(df, threshold=threshold, model_path="")
                except:
                    suggestion_df = fallback_suggest_parameters(df, threshold=threshold)
                for _, r in suggestion_df.iterrows():
                    st.session_state.auto_tune_results[int(r["layer"])] = r["suggested_params"]
                st.success("âœ… Auto-Tune å®Œæˆ")
        with col2:
            st.download_button("ğŸ’¾ ä¸‹è¼‰é æ¸¬çµæœ CSV", data=df.to_csv(index=False).encode("utf-8"), file_name="prediction_results.csv", mime="text/csv")

    # Visuals page
    if st.session_state.page == "Visuals":
        st.header("ğŸ“Š Visuals â€” Heatmap & Risk Curve & Overlays")
        st.subheader("ğŸ”¥ Heatmap")
        probs = df["prob"].values
        layers = df["layer"].values
        heat_arr = np.array(probs).reshape(-1,1)
        heat_fig = px.imshow(heat_arr, color_continuous_scale="Turbo", labels={'x':'Failure Prob','y':'Layer'})
        heat_fig.update_yaxes(tickmode="array", tickvals=list(range(len(layers))), ticktext=[str(int(x)) for x in layers])
        heat_fig.update_xaxes(showticklabels=False)
        st.plotly_chart(heat_fig, use_container_width=True)

        st.subheader("ğŸ“ˆ Risk Curve")
        curve_fig = px.line(x=df["prob"], y=df["layer"], markers=True, labels={"x":"Failure Probability","y":"Layer"})
        curve_fig.update_yaxes(autorange="reversed")
        st.plotly_chart(curve_fig, use_container_width=True)

        st.subheader("âš ï¸ High-risk Overlays")
        if len(st.session_state.overlays) == 0:
            st.info("ç›®å‰ç„¡é«˜é¢¨éšªå±¤")
        else:
            cols = st.columns(3)
            for idx,(layer,img_bytes) in enumerate(st.session_state.overlays):
                with cols[idx%3]:
                    st.image(img_bytes, caption=f"Layer {layer} (é«˜é¢¨éšª)", use_column_width=True)

    # AI Suggestions page
    if st.session_state.page == "AI Suggestions":
        st.header("ğŸ¤– AI Suggestions â€” é«˜é¢¨éšªå±¤å»ºè­°")
        df_desc = df.sort_values("prob", ascending=False).reset_index(drop=True)
        for _, row in df_desc.iterrows():
            layer = int(row["layer"])
            prob = float(row["prob"])
            st.markdown(f"### Layer {layer} â€” é¢¨éšª {prob:.3f} â€” Top3: {row['top3_features']}")
            high = (prob >= threshold)
            if not high:
                st.markdown(get_low_risk_message())
                continue

            if layer in st.session_state.llm_results:
                st.markdown("ğŸ’¡ **AI å»ºè­°ï¼ˆå·²ç”Ÿæˆï¼‰ï¼š**")
                st.markdown(st.session_state.llm_results[layer])
            else:
                btn_key = f"llm_gen_{layer}"
                if st.button(f"ç”Ÿæˆ Layer {layer} å»ºè­°", key=btn_key):
                    with st.spinner("LLM ç”Ÿæˆä¸­..."):
                        txt = get_llm_recommendation(row["params"], row["importances"])
                        st.session_state.llm_results[layer] = txt
                        st.session_state.page = "AI Suggestions"
                        st.experimental_rerun()

    # Summary page
    if st.session_state.page == "Summary":
        st.header("ğŸ“‹ Summary â€” æ‰€æœ‰å±¤å»ºè­°ç¸½è¦½")
        summary_rows = []
        for _, row in df.iterrows():
            layer = int(row["layer"])
            prob = float(row["prob"])
            high = (prob >= threshold)
            ai_text = st.session_state.llm_results.get(layer, ("ï¼ˆé«˜é¢¨éšªï¼Œå°šæœªç”Ÿæˆï¼‰" if high else "ï¼ˆä½é¢¨éšªï¼Œç„¡éœ€èª¿æ•´ï¼‰"))
            suggested_params = st.session_state.auto_tune_results.get(layer, "â€”")
            summary_rows.append({
                "layer": layer,
                "prob": round(prob,3),
                "top3_features": row["top3_features"],
                "suggested_params": suggested_params,
                "ai_suggestion": ai_text
            })
        summary_df = pd.DataFrame(summary_rows).sort_values("prob", ascending=False).reset_index(drop=True)
        st.dataframe(summary_df, use_container_width=True)
        st.download_button("ğŸ’¾ ä¸‹è¼‰å»ºè­°ç¸½è¡¨ CSV", data=summary_df.to_csv(index=False).encode("utf-8"), file_name="suggestions_summary.csv", mime="text/csv")
