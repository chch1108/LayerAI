import streamlit as st
import pandas as pd
import os
from PIL import Image

# Import the modular components of our application
from image_processor import extract_geometric_features
from model_train import load_model_and_predict, INPUT_FEATURES, CATEGORICAL_FEATURES
from llm_recommender import get_llm_recommendation

# --- Page Configuration ---
st.set_page_config(
    page_title="AI æ±ºç­–æ”¯æŒç³»çµ± (DLP 3Dåˆ—å°)",
    page_icon="ğŸ¤–",
    layout="wide"
)

# --- Application State ---
if 'history' not in st.session_state:
    st.session_state.history = []

# --- UI Layout ---
st.title("ğŸ¤– AI æ±ºç­–æ”¯æŒç³»çµ±ï¼šDLP æ¨¹è„‚å›æµé æ¸¬")
st.write("æ ¹æ“šæ‚¨è¼¸å…¥çš„ **å–®å±¤åœ–åƒ** èˆ‡ **è£½ç¨‹åƒæ•¸**ï¼Œæœ¬ç³»çµ±å°‡é æ¸¬æ¨¹è„‚å›æµæ˜¯å¦å®Œå…¨ã€‚è‹¥é æ¸¬å¤±æ•—ï¼Œå°‡ç”± AI æä¾›å„ªåŒ–å»ºè­°ã€‚")

# Create two columns for input and output
col1, col2 = st.columns(2)

# --- Column 1: User Inputs ---
with col1:
    st.header("1. è¼¸å…¥åƒæ•¸")

    # File uploader for the layer image
    uploaded_file = st.file_uploader(
        "ä¸Šå‚³å–®å±¤åˆ‡ç‰‡åœ–åƒ (Upload Layer Image)", 
        type=['png', 'jpg', 'jpeg', 'bmp']
    )

    # Input fields for process parameters
    st.subheader("è£½ç¨‹åƒæ•¸ (Process Parameters)")
    
    # Use columns for a cleaner layout
    p_col1, p_col2 = st.columns(2)
    
    with p_col1:
        viscosity = p_col1.number_input("ææ–™é»åº¦ (cps)", min_value=50, max_value=1000, value=150, step=10)
        lift_height = p_col1.number_input("æŠ¬å‡é«˜åº¦ (Î¼m)", min_value=500, max_value=8000, value=1500, step=100)
        lift_speed = p_col1.number_input("æŠ¬å‡é€Ÿåº¦ (Î¼m/s)", min_value=100, max_value=8000, value=700, step=50)

    with p_col2:
        wait_time = p_col2.number_input("ç­‰å¾…æ™‚é–“ (s)", min_value=0.0, max_value=5.0, value=0.5, step=0.1)
        down_speed = p_col2.number_input("ä¸‹é™é€Ÿåº¦ (Î¼m/s)", min_value=1000, max_value=10000, value=4000, step=500)
        shape = p_col2.selectbox("å½¢ç‹€ (Shape)", options=['90x45çŸ©å½¢', '90x50å…­è§’å½¢', '50åœ“æŸ±'])

    # Predict button
    predict_button = st.button("åŸ·è¡Œé æ¸¬ (Run Prediction)", type="primary")


# --- Column 2: Prediction and Recommendation ---
with col2:
    st.header("2. é æ¸¬çµæœèˆ‡å»ºè­°")

    if predict_button:
        # --- Input Validation ---
        if uploaded_file is None:
            st.error("è«‹å…ˆä¸Šå‚³åœ–åƒæ–‡ä»¶ã€‚" )
        else:
            with st.spinner("è™•ç†ä¸­... æ­£åœ¨åˆ†æåœ–åƒä¸¦åŸ·è¡Œé æ¸¬..."):
                # --- 1. Image Processing ---
                # Save the uploaded file temporarily to be processed by OpenCV
                temp_image_path = f"temp_{uploaded_file.name}"
                with open(temp_image_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                
                geo_features = extract_geometric_features(temp_image_path)
                
                # Clean up the temporary file
                os.remove(temp_image_path)

                if geo_features is None:
                    st.error("åœ–åƒè™•ç†å¤±æ•—ï¼Œè«‹æª¢æŸ¥åœ–åƒæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆã€‚" )
                else:
                    st.info(f"åœ–åƒç‰¹å¾µæå–æˆåŠŸï¼š\n" 
                            f"- é¢ç©: {geo_features['area']:.2f} mmÂ²\n" 
                            f"- å‘¨é•·: {geo_features['perimeter']:.2f} mm\n" 
                            f"- æ°´åŠ›ç›´å¾‘: {geo_features['hydraulic_diameter']:.2f} mm")

                    # --- 2. Prepare Data for Model ---
                    input_data = {
                        'ææ–™é»åº¦ (cps)': viscosity,
                        'æŠ¬å‡é«˜åº¦(Î¼m)': lift_height,
                        'æŠ¬å‡é€Ÿåº¦(Î¼m/s)': lift_speed,
                        'ç­‰å¾…æ™‚é–“(s)': wait_time,
                        'ä¸‹é™é€Ÿåº¦((Î¼m)/s)': down_speed,
                        'å½¢ç‹€': shape,
                        'é¢ç©(mm?)': geo_features['area'],
                        'å‘¨é•·(mm)': geo_features['perimeter'],
                        'æ°´åŠ›ç›´å¾‘(mm)': geo_features['hydraulic_diameter']
                    }
                    
                    # Ensure all required features are present
                    final_input_data = {feat: input_data.get(feat) for feat in INPUT_FEATURES}
                    input_df = pd.DataFrame([final_input_data])

                    # --- 3. Run Prediction ---
                    try:
                        prediction, importances = load_model_and_predict(input_df)
                        
                        # --- 4. Display Results ---
                        if prediction == 0:
                            st.success("âœ… **é æ¸¬æˆåŠŸï¼šæ¨¹è„‚å›æµå®Œå…¨**")
                            st.write("ç›®å‰çš„åƒæ•¸è¨­å®šåœ¨æ­¤å±¤æ˜¯å®‰å…¨çš„ï¼Œå¯ä»¥ç¹¼çºŒåˆ—å°ã€‚" )
                        else:
                            st.error("ğŸš¨ **é æ¸¬å¤±æ•—ï¼šæ¨¹è„‚å›æµä¸å®Œå…¨**")
                            st.write("åµæ¸¬åˆ°æ½›åœ¨çš„åˆ—å°å¤±æ•—é¢¨éšªã€‚æ­£åœ¨å‘ AI å°‹æ±‚å„ªåŒ–å»ºè­°..." )
                            
                            # --- 5. Get LLM Recommendation ---
                            with st.spinner("æ­£åœ¨ç”Ÿæˆ AI å»ºè­°..."):
                                recommendation = get_llm_recommendation(final_input_data, importances)
                                st.markdown("---")
                                st.subheader("ğŸ¤– AI å„ªåŒ–å»ºè­°")
                                st.markdown(recommendation)

                    except FileNotFoundError as e:
                        st.error(f"æ¨¡å‹æ–‡ä»¶éºå¤±ï¼š{e}\n\nè«‹å…ˆåŸ·è¡Œ `python model_train.py` ä¾†è¨“ç·´ä¸¦ç”Ÿæˆæ¨¡å‹æ–‡ä»¶ã€‚" )
                    except Exception as e:
                        st.error(f"é æ¸¬æ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# --- Optional: Display History ---
# This is a simple implementation. For a real app, you might want a more robust solution.
# st.header("æ­·å²ç´€éŒ„")
# if st.session_state.history:
#     for i, record in enumerate(st.session_state.history[-5:]): # Show last 5
#         st.json(record)
# else:
#     st.info("å°šç„¡é æ¸¬ç´€éŒ„ã€‚" )
